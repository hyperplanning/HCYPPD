{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "277a57d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import palettable\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import gc\n",
    "\n",
    "data = pd.read_parquet(\"data/raw/france.parquet\")\n",
    "\n",
    "data.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "data[\"id\"] = [i for i in range(len(data))]\n",
    "data[\"time\"] = data.index\n",
    "data = data.set_index(\"id\")\n",
    "all_years = []\n",
    "all_month = []\n",
    "for t in range(len(data)):\n",
    "    all_years.append(data[\"time\"][t].year)\n",
    "    all_month.append(data[\"time\"][t].month)\n",
    "data[\"year\"] = all_years\n",
    "data[\"month\"] = all_month\n",
    "data = data.drop([\"time\"], axis=1)\n",
    "\n",
    "position = pd.read_csv(\"data/raw/postesSynop.csv\", sep=\";\")\n",
    "\n",
    "Id = position[\"ID\"].astype(str)\n",
    "for i in range(len(Id)):\n",
    "    if len(Id[i]) < 5:\n",
    "        Id[i] = '0' + Id[i]\n",
    "\n",
    "production = pd.read_parquet(\"data/raw/franceagrimer-rdts-surfs-multicrops.parquet\")\n",
    "\n",
    "production = production.drop(production[production[\"n_dep\"] == \"2A\"].index)\n",
    "production = production.drop(production[production[\"n_dep\"] == \"2B\"].index)\n",
    "production = production.drop(production[production[\"n_dep\"].astype(int) > 95].index)\n",
    "\n",
    "provinces = {7005: 80, 7015: 59, 7020: 50, 7027: 14, 7037: 76,\n",
    "             7072: 51, 7110: 29, 7117: 22, 7130: 35, 7139: 61,\n",
    "             7149: 91, 7168: 10, 7181: 54, 7190: 67, 7207: 56,\n",
    "             7222: 44, 7240: 37, 7255: 18, 7280: 21, 7299: 68,\n",
    "             7314: 17, 7335: 86, 7434: 87, 7460: 63, 7471: 43,\n",
    "             7481: 69, 7510: 33, 7535: 46, 7558: 12, 7577: 26,\n",
    "             7591: 5, 7607: 40, 7621: 65, 7627: 9, 7630: 31,\n",
    "             7643: 34, 7650: 13, 7661: 83, 7690: 6, 7747: 66,\n",
    "             7761: 91, 67005: 10}\n",
    "\n",
    "stations = data[\"id_sta\"].unique()\n",
    "unwanted_stations = []\n",
    "for i in stations:\n",
    "    if i not in provinces:\n",
    "        unwanted_stations.append(i)\n",
    "for i in unwanted_stations:\n",
    "    data = data.drop(data[data[\"id_sta\"] == i].index)\n",
    "\n",
    "temp_province = []\n",
    "for i in data[\"id_sta\"]:\n",
    "    temp_province.append(provinces[i])\n",
    "data[\"province\"] = temp_province\n",
    "data = data.drop([\"id_sta\"], axis=1)\n",
    "\n",
    "years = data[\"year\"].unique()\n",
    "provinces = data[\"province\"].unique()\n",
    "crops = production[\"crop\"].unique()\n",
    "n_deps = production[\"n_dep\"].unique()\n",
    "\n",
    "working_month = {\"OP\": [3, 4, 5, 6, 7, 8], \"CZH\": [9, 10, 11, 12, 1, 2, 3, 4, 5, 6, 7],\n",
    "                 \"BTH\": [9, 10, 11, 12, 1, 2, 3, 4, 5, 6, 7], \"TS\": [3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
    "                 \"BTP\": [2, 3, 4, 5, 6, 7, 8], \"BDP\": [2, 3, 4, 5, 6, 7, 8],\n",
    "                 \"BDH\": [9, 10, 11, 12, 1, 2, 3, 4, 5, 6, 7], \"OH\": [9, 10, 11, 12, 1, 2, 3, 4, 5, 6, 7],\n",
    "                 \"MA\": [4, 5, 6, 7, 8, 9, 10, 11]}\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "sns.set(rc={'figure.figsize': (11, 9)})\n",
    "\n",
    "\n",
    "def read_in_Y(crop, consider_part):\n",
    "    crop_Y_year = {}\n",
    "\n",
    "    map_crop = production['crop'].map(lambda x: x == crop)\n",
    "    crop_value = production[map_crop]\n",
    "\n",
    "    for n in n_deps:\n",
    "        map_province = crop_value['n_dep'].map(lambda x: x == n)\n",
    "        crop_n_value = crop_value[map_province]\n",
    "\n",
    "        for y in years:\n",
    "            if len(crop_n_value[consider_part + \"_\" + str(y)].values):\n",
    "                rdt_value = crop_n_value[consider_part + \"_\" + str(y)].values[0]\n",
    "\n",
    "                if rdt_value:\n",
    "                    crop_Y_year[crop + \"_\" + str(int(n)) + \"_\" + str(y)] = rdt_value\n",
    "\n",
    "    return crop_Y_year\n",
    "\n",
    "\n",
    "def read_in_Ys():\n",
    "    for crop in crops:\n",
    "        if crop not in crops_Y_year:\n",
    "            crops_Y_year[crop] = read_in_Y(crop, \"rdt\")\n",
    "\n",
    "\n",
    "def X_devide_region(consider_X):\n",
    "    for p in provinces:\n",
    "        temp_p_data = data[data[\"province\"].map(lambda x: x == p)]\n",
    "\n",
    "        for y in years:\n",
    "            temp_py_data = temp_p_data[temp_p_data[\"year\"].map(lambda x: x == y)]\n",
    "\n",
    "            for m in range(1, 13):\n",
    "                temp_pym_data = temp_py_data[temp_py_data[\"month\"].map(lambda x: x == m)]\n",
    "\n",
    "                if consider_X[0] in temp_pym_data and temp_pym_data[consider_X[0]].tolist():\n",
    "                    for x in consider_X:\n",
    "                        name = str(p) + \"_\" + str(y) + \"_\" + str(m)\n",
    "                        if name not in X_region_year_month:\n",
    "                            X_region_year_month[name] = [temp_pym_data[x].tolist()]\n",
    "                        else:\n",
    "                            X_region_year_month[name].append(temp_pym_data[x].tolist())\n",
    "\n",
    "\n",
    "def normalize_X():\n",
    "    for i in X_region_year_month:\n",
    "        X_region_year_month_normalized[i] = []\n",
    "\n",
    "        for j in X_region_year_month[i]:\n",
    "            temp_array = np.array(j)\n",
    "            max_X, min_X = max(temp_array), min(temp_array)\n",
    "\n",
    "            if max_X - min_X > 1.0e-15:\n",
    "                X_region_year_month_normalized[i].append(((temp_array - min_X) / (max_X - min_X)).tolist())\n",
    "            else:\n",
    "                X_region_year_month_normalized[i].append([len(j) - 1 for _ in j])\n",
    "\n",
    "\n",
    "def average_X():\n",
    "    for i in X_region_year_month_normalized:\n",
    "        X_region_year_normalized_average[i] = []\n",
    "        for j in range(len(X_region_year_month_normalized[i])):\n",
    "            X_region_year_normalized_average[i].append(np.average(X_region_year_month_normalized[i][j]))\n",
    "\n",
    "\n",
    "def init_list(crop, consider_part, province, month):\n",
    "    X = []\n",
    "    Y = []\n",
    "    crop_Y_year = crops_Y_year[crop]\n",
    "\n",
    "    if consider_part not in X_consider_part:\n",
    "        temp_X = {}\n",
    "        for i in X_region_year_normalized_average:\n",
    "            temp_X[i] = X_region_year_normalized_average[i][consider_part]\n",
    "        X_consider_part[consider_part] = temp_X\n",
    "    else:\n",
    "        temp_X = X_consider_part[consider_part]\n",
    "\n",
    "    for i in temp_X:\n",
    "        p, y, m = i.split(\"_\")\n",
    "        if int(p) == province and int(m) == month:\n",
    "            name = crop + \"_\" + p + \"_\" + y\n",
    "            if name in crop_Y_year:\n",
    "                X.append(temp_X[i])\n",
    "                Y.append(crop_Y_year[name])\n",
    "\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "\n",
    "def add_power(X, powers):\n",
    "    powered_X = []\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        powered_X.append([])\n",
    "\n",
    "        for j in range(len(X[i])):\n",
    "            temp_list = []\n",
    "            for p in range(1, powers[j] + 1):\n",
    "                temp_list.append(X[i][j] ** p)\n",
    "            for t in temp_list:\n",
    "                powered_X[-1].append(t)\n",
    "\n",
    "    return powered_X\n",
    "\n",
    "\n",
    "def correlation(X, Y):\n",
    "    if len(X) < 3 or len(Y) < 3:\n",
    "        return 0.0\n",
    "\n",
    "    avg_X = np.average(X)\n",
    "    avg_Y = np.average(Y)\n",
    "\n",
    "    cr = 0\n",
    "    nx = 0\n",
    "    ny = 0\n",
    "    for i in range(len(X)):\n",
    "        cr += (X[i] - avg_X) * (Y[i] - avg_Y)\n",
    "        nx += (X[i] - avg_X) ** 2\n",
    "        ny += (Y[i] - avg_Y) ** 2\n",
    "\n",
    "    if math.sqrt(nx) * math.sqrt(ny) > 1.0e-15:\n",
    "        r = cr / (math.sqrt(nx) * math.sqrt(ny))\n",
    "    else:\n",
    "        r = 0.0\n",
    "\n",
    "    return r\n",
    "\n",
    "\n",
    "def predict_zero(data_Y_array):\n",
    "    zero = data_Y_array.mean()\n",
    "\n",
    "    RMSE = math.sqrt(((zero - data_Y_array) ** 2).sum() / len(data_Y_array))\n",
    "    rRMSE = RMSE / data_Y_array.mean()\n",
    "\n",
    "    return rRMSE\n",
    "\n",
    "\n",
    "def predict_XY(times, X, Y):\n",
    "    sum_RMSE = 0\n",
    "    coef = np.array([0.0 for i in range(len(X[0]))])\n",
    "    intercept = 0.0\n",
    "\n",
    "    for i in range(times):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "        lr.fit(X_train, y_train)\n",
    "\n",
    "        coef += lr.coef_\n",
    "        intercept += lr.intercept_\n",
    "\n",
    "        y_predict = lr.predict(X_test)\n",
    "\n",
    "        RMSE = math.sqrt(((y_predict - y_test) ** 2).sum() / len(y_test))\n",
    "        rRMSE = RMSE / y_test.mean()\n",
    "\n",
    "        sum_RMSE += rRMSE\n",
    "\n",
    "    return sum_RMSE / times, coef / times, intercept / times\n",
    "\n",
    "\n",
    "def get_correltion():\n",
    "    for p in provinces:\n",
    "        consider_parts_list = []\n",
    "        correlations = {}\n",
    "        correlations_list = []\n",
    "\n",
    "        for cp in range(len(consider_parts)):\n",
    "            for m in range(1, 13):\n",
    "                correlations_list.append([])\n",
    "                consider_parts_list.append(consider_parts[cp] + \"_\" + str(m))\n",
    "\n",
    "                for crop in crops:\n",
    "                    X, Y = init_list(crop, cp, p, m)\n",
    "                    correlations[crop + \"_\" + consider_parts[cp] + \"_\" + str(m)] = correlation(X, Y)\n",
    "                    correlations_list[-1].append(correlations[crop + \"_\" + consider_parts[cp] + \"_\" + str(m)])\n",
    "\n",
    "        c_plot = pd.DataFrame(data=correlations_list, columns=crops)\n",
    "        c_plot[\"type\"] = consider_parts_list\n",
    "        c_plot = c_plot.set_index(\"type\")\n",
    "        correlation_province[p] = c_plot\n",
    "\n",
    "\n",
    "def treat_noise():\n",
    "    provinces = list(correlation_province.keys())\n",
    "\n",
    "    for c in consider_parts:\n",
    "        for crop in crops:\n",
    "            for p in provinces:\n",
    "                temp_list = [correlation_province[p][crop][c + \"_\" + str(i)] for i in range(1, 13)]\n",
    "                temp_list.sort()\n",
    "                for i in range(max_hold):\n",
    "                    if math.fabs(temp_list[0]) > math.fabs(temp_list[-1]):\n",
    "                        temp_list.pop(0)\n",
    "                    else:\n",
    "                        temp_list.pop(-1)\n",
    "\n",
    "                for i in range(1, 13):\n",
    "                    temp_c = correlation_province[p][crop][c + \"_\" + str(i)]\n",
    "\n",
    "                    if temp_c in temp_list:\n",
    "                        temp_list.remove(temp_c)\n",
    "                        correlation_province[p][crop][c + \"_\" + str(i)] = 0.0\n",
    "\n",
    "\n",
    "def do_cluster(cut_number=0.2):\n",
    "    for c in consider_parts:\n",
    "        for crop in crops:\n",
    "            X = []\n",
    "\n",
    "            for p in provinces:\n",
    "                X.append([])\n",
    "\n",
    "                for i in range(1, 13):\n",
    "                    X[-1].append(correlation_province[p][crop][c + \"_\" + str(i)])\n",
    "\n",
    "            for nc in n_clusters_apply:\n",
    "                if str(len(X)) + \"_\" + str(nc) not in var_limits:\n",
    "                    global_var(len(X), nc, cut_number)\n",
    "\n",
    "                for aa in affinity_apply:\n",
    "                    for la in linkage_apply:\n",
    "                        if la == \"ward\" and aa != \"euclidean\":\n",
    "                            continue\n",
    "                        if aa == \"cosine\" and [0.0 for _ in range(12)] in X:\n",
    "                            continue\n",
    "\n",
    "                        clustering = AgglomerativeClustering(n_clusters=nc, affinity=aa, linkage=la).fit(X)\n",
    "                        var_counts = [list(clustering.labels_).count(i) for i in range(nc)]\n",
    "                        var_counts = math.sqrt(np.var(var_counts))\n",
    "                        if var_counts < var_limits[str(len(X)) + \"_\" + str(nc)]:\n",
    "                            clustering_result[c + \"_\" + crop + \"_\" + str(nc) + \"_\" + aa + \"_\" + la] = clustering.labels_\n",
    "\n",
    "\n",
    "def evaluate_clusters():\n",
    "    for cr in clustering_result:\n",
    "        gc.collect()\n",
    "\n",
    "        try:\n",
    "            c, crop, nc, aa, la = cr.split(\"_\")\n",
    "        except Exception:\n",
    "            c1, c2, crop, nc, aa, la = cr.split(\"_\")\n",
    "            c = c1 + \"_\" + c2\n",
    "\n",
    "        cr_array = clustering_result[cr]\n",
    "        province_cluster_groups = [[] for _ in range(int(nc))]\n",
    "\n",
    "        for p in range(len(provinces)):\n",
    "            province_cluster_groups[cr_array[p]].append(provinces[p])\n",
    "\n",
    "        for pcg in range(len(province_cluster_groups)):\n",
    "            X = []\n",
    "            Y = []\n",
    "\n",
    "            for p in province_cluster_groups[pcg]:\n",
    "                for m in range(1, 13):\n",
    "                    temp_X, temp_Y = init_list(crop, consider_parts.index(c), p, m)\n",
    "                    temp_X, temp_Y = list(temp_X), list(temp_Y)\n",
    "                    X += temp_X\n",
    "                    Y += temp_Y\n",
    "\n",
    "            all_amount[cr + \"_\" + str(pcg)] = len(Y)\n",
    "\n",
    "            cluster_evaluate_result[cr + \"_\" + str(pcg)] = [predict_zero(np.array(Y)) * len(Y)]\n",
    "\n",
    "            X = np.array(X).reshape(-1, 1)\n",
    "            Y = np.array(Y)\n",
    "            for d in degrees:\n",
    "                powered_X = add_power(X, [d])\n",
    "                rRMSE = predict_XY(times, powered_X, Y)[0]\n",
    "                cluster_evaluate_result[cr + \"_\" + str(pcg)].append(rRMSE * len(Y))\n",
    "\n",
    "        all_cluster_rRMSE[cr] = 0.0\n",
    "        temp_number = sum([all_amount[cr + \"_\" + str(pcg)] for pcg in range(len(province_cluster_groups))])\n",
    "\n",
    "        for i in range(int(nc)):\n",
    "            temp_list = cluster_evaluate_result[cr + \"_\" + str(i)]\n",
    "            all_cluster_rRMSE[cr] += min(temp_list) / temp_number\n",
    "\n",
    "        cluster_evaluate_result.clear()\n",
    "        all_amount.clear()\n",
    "\n",
    "\n",
    "def global_var(length, type_number, cut_number=0.2):\n",
    "    if math.factorial(length - 1) / (math.factorial(type_number - 1) * math.factorial(length - type_number)) > 1.0e+6:\n",
    "        for i in range(2, type_number):\n",
    "            if str(length) + \"_\" + str(i) not in var_limits:\n",
    "                global_var(length, i, cut_number)\n",
    "\n",
    "        percents = np.average([var_limits[str(length) + \"_\" + str(i + 1)] / var_limits[str(length) + \"_\" + str(i)] for i in range(2, type_number - 1)])\n",
    "        var_limits[str(length) + \"_\" + str(type_number)] = var_limits[str(length) + \"_\" + str(type_number - 1)] * percents\n",
    "        return\n",
    "\n",
    "    temp_var_limits = {}\n",
    "\n",
    "    for tn in range(2, type_number + 1):\n",
    "        if str(length) + \"_\" + str(tn) in var_limits:\n",
    "            continue\n",
    "\n",
    "        dist_list = [[i] for i in range(1, length)]\n",
    "        next_dist_list = []\n",
    "\n",
    "        for t in range(tn - 2):\n",
    "            for i in dist_list:\n",
    "                for j in range(1, length + 1):\n",
    "                    if sum(i) + j < length:\n",
    "                        next_dist_list.append(i + [j])\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "            dist_list = next_dist_list\n",
    "            next_dist_list = []\n",
    "\n",
    "        for i in dist_list:\n",
    "            i.append(length - sum(i))\n",
    "\n",
    "        temp_var_limits[tn] = [math.sqrt(np.var(k)) for k in dist_list]\n",
    "        temp_var_limits[tn].sort()\n",
    "\n",
    "    for vl in temp_var_limits:\n",
    "        count = 0\n",
    "        for v in temp_var_limits[vl]:\n",
    "            if v > cut_number * temp_var_limits[vl][-1]:\n",
    "                count += 1\n",
    "        var_limits[str(length) + \"_\" + str(vl)] = temp_var_limits[vl][count]\n",
    "\n",
    "\n",
    "def get_best_in_degree():\n",
    "    for cr in all_cluster_rRMSE:\n",
    "        try:\n",
    "            c, crop, nc, aa, la = cr.split(\"_\")\n",
    "        except Exception:\n",
    "            c1, c2, crop, nc, aa, la = cr.split(\"_\")\n",
    "            c = c1 + \"_\" + c2\n",
    "\n",
    "        name = c + \"_\" + crop + \"_\" + str(nc)\n",
    "        if name not in best_cluster_rRMSE or all_cluster_rRMSE[cr] < best_cluster_rRMSE[name]:\n",
    "            best_cluster_rRMSE[name] = all_cluster_rRMSE[cr]\n",
    "            best_cluster_param[name] = aa + \"_\" + la\n",
    "\n",
    "\n",
    "def get_best_model_no_over(cut_number=0.2):\n",
    "    for cp in consider_parts:\n",
    "        for crop in crops:\n",
    "            temp_list = []\n",
    "            temp_list_index = []\n",
    "            name = cp + \"_\" + crop\n",
    "\n",
    "            for nca in n_clusters_apply:\n",
    "                if name + \"_\" + str(nca) in best_cluster_rRMSE:\n",
    "                    temp_list.append(best_cluster_rRMSE[name + \"_\" + str(nca)])\n",
    "                    temp_list_index.append(nca)\n",
    "\n",
    "            temp_diff = temp_list[0] - temp_list[1]\n",
    "            for i in range(1, len(temp_list) - 1):\n",
    "                d = temp_list[i] - temp_list[i + 1]\n",
    "\n",
    "                if d < 0 or d / (temp_diff + d) < cut_number:\n",
    "                    best_model_not_overmodel[cp + \"_\" + crop] = temp_list_index[i]\n",
    "                    break\n",
    "                elif i == len(temp_list) - 2:\n",
    "                    best_model_not_overmodel[cp + \"_\" + crop] = -1\n",
    "                else:\n",
    "                    temp_diff += d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a09756c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# READ IN\n",
    "\n",
    "consider_parts = [\"rr24\", \"t_avg\"]\n",
    "\n",
    "X_region_year_month = {}\n",
    "X_region_year_month_normalized = {}\n",
    "X_region_year_normalized_average = {}\n",
    "crops_Y_year = {}\n",
    "X_consider_part = {}\n",
    "\n",
    "X_devide_region(consider_parts)\n",
    "normalize_X()\n",
    "average_X()\n",
    "read_in_Ys()\n",
    "\n",
    "del X_region_year_month\n",
    "del X_region_year_month_normalized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c92d788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRELATION CALCULATE\n",
    "\n",
    "correlation_province = {}\n",
    "\n",
    "get_correltion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2ec8136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOISE TREAT\n",
    "\n",
    "max_hold = 4\n",
    "\n",
    "treat_noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b68a782c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CLUSTER WITH AGGLOMERATIVE\n",
    "\n",
    "n_clusters_apply = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "affinity_apply = [\"euclidean\", \"l1\", \"l2\", \"manhattan\", \"cosine\"]\n",
    "linkage_apply = [\"ward\", \"complete\", \"average\", \"single\"]\n",
    "clustering_result = {}\n",
    "var_limits = {}\n",
    "\n",
    "do_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b85b8cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE\n",
    "\n",
    "degrees = [1, 2, 3, 4, 5, 6]\n",
    "times = 100\n",
    "\n",
    "cluster_evaluate_result = {}\n",
    "all_cluster_rRMSE = {}\n",
    "all_amount = {}\n",
    "\n",
    "evaluate_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6dede172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET BEST AMONG DEGREE\n",
    "\n",
    "best_cluster_rRMSE = {}\n",
    "best_cluster_param = {}\n",
    "\n",
    "get_best_in_degree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "985462bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET BEST MODEL NOT OVERMODEL\n",
    "\n",
    "best_model_not_overmodel = {}\n",
    "\n",
    "get_best_model_no_over()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "666cf51d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rr24_OP: 6 parts\n",
      "Part 0: 76, 29, 44, 34, 66\n",
      "Part 1: 59, 14, 35, 54, 67, 56, 21, 68, 87, 40, 9, 31, 13\n",
      "Part 2: 22, 63, 43, 69, 26, 5, 65\n",
      "Part 3: 61, 18, 17, 86, 46\n",
      "Part 4: 80, 91, 10, 33\n",
      "Part 5: 50, 51, 37, 12, 83, 6\n",
      "rRMSE: 0.22333546893157336\n",
      "\n",
      "rr24_CZH: 5 parts\n",
      "Part 0: 80, 59, 76, 12, 40, 31\n",
      "Part 1: 50, 35, 61, 10, 56, 21, 17, 33, 5, 83, 6, 66\n",
      "Part 2: 68, 63, 43\n",
      "Part 3: 51, 54, 69, 34\n",
      "Part 4: 14, 29, 22, 91, 67, 44, 37, 18, 86, 87, 46, 26, 65, 9, 13\n",
      "rRMSE: 0.20343545126434906\n",
      "\n",
      "rr24_BTH: 4 parts\n",
      "Part 0: 80, 59, 50, 76, 22, 61, 91, 56, 44, 37, 68, 17, 86, 69, 33, 46, 65, 9, 31, 66\n",
      "Part 1: 14, 51, 29, 35, 10, 54, 67, 12, 5, 6\n",
      "Part 2: 18, 21, 87, 43, 40, 34\n",
      "Part 3: 63, 26, 13, 83\n",
      "rRMSE: 0.24759659928524555\n",
      "\n",
      "rr24_TS: 4 parts\n",
      "Part 0: 80, 59, 76, 21, 63, 43, 69, 26, 9, 13\n",
      "Part 1: 50, 29, 56, 68, 87, 12, 5, 40, 34, 83, 6, 66\n",
      "Part 2: 14, 51, 22, 35, 61, 10, 54, 67, 44, 37, 18, 17, 86, 33, 46, 31\n",
      "Part 3: 91, 65\n",
      "rRMSE: 0.17937545630851967\n",
      "\n",
      "rr24_BTP: 5 parts\n",
      "Part 0: 80, 59, 14, 76, 51, 29, 91, 10, 67, 56, 44, 68, 17, 86, 87, 33, 46, 12, 5, 65, 9, 34, 13, 66\n",
      "Part 1: 43, 69, 83\n",
      "Part 2: 18, 21, 63, 26, 40\n",
      "Part 3: 54, 6\n",
      "Part 4: 50, 22, 35, 61, 37, 31\n",
      "rRMSE: 0.2677979953434219\n",
      "\n",
      "rr24_BDP: 6 parts\n",
      "Part 0: 80, 29, 87, 12, 5, 9\n",
      "Part 1: 22, 17, 31\n",
      "Part 2: 91, 44, 18, 33, 40\n",
      "Part 3: 35, 10, 56\n",
      "Part 4: 51, 37, 86\n",
      "Part 5: 59, 50, 14, 76, 61, 54, 67, 21, 68, 63, 43, 69, 46, 26, 65, 34, 13, 83, 6, 66\n",
      "rRMSE: 0.20794727625856932\n",
      "\n",
      "rr24_BDH: 6 parts\n",
      "Part 0: 80, 29, 87, 12, 5, 9\n",
      "Part 1: 22, 17, 31\n",
      "Part 2: 91, 44, 18, 33, 40\n",
      "Part 3: 35, 10, 56\n",
      "Part 4: 51, 37, 86\n",
      "Part 5: 59, 50, 14, 76, 61, 54, 67, 21, 68, 63, 43, 69, 46, 26, 65, 34, 13, 83, 6, 66\n",
      "rRMSE: 0.20779224197248236\n",
      "\n",
      "rr24_OH: 7 parts\n",
      "Part 0: 59, 14, 76, 35, 18, 86, 12, 5, 34\n",
      "Part 1: 43, 26, 83\n",
      "Part 2: 80, 51, 54, 56, 6\n",
      "Part 3: 68\n",
      "Part 4: 50, 29, 22, 61, 91, 10, 67, 44, 37, 87, 69, 65, 9, 13\n",
      "Part 5: 66\n",
      "Part 6: 21, 17, 63, 33, 46, 40, 31\n",
      "rRMSE: 0.19443209431381056\n",
      "\n",
      "rr24_MA: 4 parts\n",
      "Part 0: 80, 59, 14, 51, 35, 61, 91, 54, 67, 56, 44, 21, 17, 86, 87, 63, 33, 12, 65, 9, 13, 6\n",
      "Part 1: 76, 43, 69, 46, 26, 5, 34, 66\n",
      "Part 2: 40, 31\n",
      "Part 3: 50, 29, 22, 10, 37, 18, 68, 83\n",
      "rRMSE: 0.2026152921001993\n",
      "\n",
      "t_avg_OP: 3 parts\n",
      "Part 0: 50, 22, 35, 67, 56, 68, 87, 12, 34, 66\n",
      "Part 1: 29, 63, 69, 26, 5, 40, 65, 31, 13, 6\n",
      "Part 2: 80, 59, 14, 76, 51, 61, 91, 10, 54, 44, 37, 18, 21, 17, 86, 43, 33, 46, 9, 83\n",
      "rRMSE: 0.22465601771671612\n",
      "\n",
      "t_avg_CZH: 5 parts\n",
      "Part 0: 29, 91, 18, 17, 86, 26, 40, 9\n",
      "Part 1: 80, 59, 50, 14, 54, 63, 69, 12\n",
      "Part 2: 76, 51, 22, 10, 56, 21, 33, 34, 83\n",
      "Part 3: 61, 44, 37, 87, 46\n",
      "Part 4: 35, 67, 68, 43, 5, 65, 31, 13, 6, 66\n",
      "rRMSE: 0.2014394312352342\n",
      "\n",
      "t_avg_BTH: 4 parts\n",
      "Part 0: 35, 61, 91, 56, 44, 37, 18, 21, 17, 86, 87, 69, 33, 46, 5, 65, 9, 31, 34, 13, 83, 66\n",
      "Part 1: 63, 43, 12, 26\n",
      "Part 2: 80, 59, 50, 76, 29, 22, 40, 6\n",
      "Part 3: 14, 51, 10, 54, 67, 68\n",
      "rRMSE: 0.22647457278408764\n",
      "\n",
      "t_avg_TS: 4 parts\n",
      "Part 0: 80, 59, 22, 35, 91, 10, 54, 67, 44, 37, 18, 21, 17, 86, 63, 43, 33, 26, 9, 31, 83, 66\n",
      "Part 1: 50, 14, 76, 51, 61, 87, 69, 46, 12, 6\n",
      "Part 2: 29, 56, 68, 5, 13\n",
      "Part 3: 40, 65, 34\n",
      "rRMSE: 0.18535949891479492\n",
      "\n",
      "t_avg_BTP: 5 parts\n",
      "Part 0: 50, 76, 29, 22, 35, 61, 91, 56, 44, 37, 18, 21, 17, 86, 87, 43, 69, 33, 40, 9, 34, 13, 83, 66\n",
      "Part 1: 63, 12, 26, 5\n",
      "Part 2: 80, 59, 14, 65\n",
      "Part 3: 51, 10, 54, 67, 68, 46, 31\n",
      "Part 4: 6\n",
      "rRMSE: 0.24901140051217646\n",
      "\n",
      "t_avg_BDP: 5 parts\n",
      "Part 0: 59, 50, 14, 76, 61, 54, 67, 37, 18, 21, 68, 17, 63, 43, 69, 33, 46, 26, 40, 65, 34, 13, 83, 6, 66\n",
      "Part 1: 44, 9, 31\n",
      "Part 2: 51, 29, 22, 35, 56\n",
      "Part 3: 10, 86, 87, 12, 5\n",
      "Part 4: 80, 91\n",
      "rRMSE: 0.20197630306482092\n",
      "\n",
      "t_avg_BDH: 5 parts\n",
      "Part 0: 59, 50, 14, 76, 61, 54, 67, 37, 18, 21, 68, 17, 63, 43, 69, 33, 46, 26, 40, 65, 34, 13, 83, 6, 66\n",
      "Part 1: 44, 9, 31\n",
      "Part 2: 51, 29, 22, 35, 56\n",
      "Part 3: 10, 86, 87, 12, 5\n",
      "Part 4: 80, 91\n",
      "rRMSE: 0.20030182194309432\n",
      "\n",
      "t_avg_OH: 5 parts\n",
      "Part 0: 63, 12, 26, 5, 34, 6\n",
      "Part 1: 14, 76, 51, 29, 35, 61, 91, 10, 54, 44, 37, 18, 21, 86, 87, 69, 33, 9, 31\n",
      "Part 2: 46, 65, 83, 66\n",
      "Part 3: 50, 22, 56, 17, 43, 40, 13\n",
      "Part 4: 80, 59, 67, 68\n",
      "rRMSE: 0.17911366651024638\n",
      "\n",
      "t_avg_MA: 5 parts\n",
      "Part 0: 80, 59, 50, 51, 29, 22, 35, 61, 91, 10, 54, 67, 56, 44, 21, 68, 17, 87, 63, 43, 40, 65, 13, 83, 6\n",
      "Part 1: 14, 76, 37, 18, 86, 69, 33, 46, 12, 26, 9, 31\n",
      "Part 2: 34\n",
      "Part 3: 5\n",
      "Part 4: 66\n",
      "rRMSE: 0.1784564479731321\n",
      "\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "# PRINT RESULT\n",
    "\n",
    "for i in best_model_not_overmodel:\n",
    "    if best_model_not_overmodel[i] != -1:\n",
    "        print(i + \": \" + str(best_model_not_overmodel[i]) + \" parts\")\n",
    "\n",
    "        name = i + \"_\" + str(best_model_not_overmodel[i])\n",
    "        name = name + \"_\" + best_cluster_param[name]\n",
    "\n",
    "        best_cluster_result = clustering_result[name]\n",
    "        province_cluster_groups = [[] for j in range(best_model_not_overmodel[i])]\n",
    "        for p in range(len(provinces)):\n",
    "            province_cluster_groups[best_cluster_result[p]].append(provinces[p])\n",
    "        for j in range(len(province_cluster_groups)):\n",
    "            print(\"Part \" + str(j) + \": \" + str(province_cluster_groups[j])[1: -1])\n",
    "            \n",
    "        print(\"rRMSE: \" + str(best_cluster_rRMSE[i + \"_\" + str(best_model_not_overmodel[i])]))\n",
    "\n",
    "        print()\n",
    "\n",
    "\n",
    "print(\"End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084791a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
